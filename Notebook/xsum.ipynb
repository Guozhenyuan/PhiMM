{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XSUM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since EdinburghNLP/xsum couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/EdinburghNLP___xsum/default/1.2.0/40db7604fedb616a9d2b0673d11838fa5be8451c (last modified on Tue Nov 19 11:55:43 2024).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ['https_proxy'] = 'http://10.14.30.39:7890'\n",
    "\n",
    "ds = load_dataset(\"EdinburghNLP/xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'summary', 'id'],\n",
       "    num_rows: 204045\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = ds['train']\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9df3f78ed54d5fbef83b0999d51b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=48):   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 四分位数: 106.0, 中位数: 126.0, 第 3 四分位数: 144.0\n",
      "mean: 125.46304981744223\n"
     ]
    }
   ],
   "source": [
    "def map_len_summary(example):\n",
    "    example['len_sum']=len(example['summary'])\n",
    "    return example\n",
    "\n",
    "train_ds = train_ds.map(map_len_summary,num_proc=48)\n",
    "\n",
    "\n",
    "len_mate_data = train_ds['len_sum']\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_quartiles_with_pandas(data):\n",
    "    \"\"\"\n",
    "    使用 Pandas 计算数据的四分位数\n",
    "    :param data: 数据列表或数组\n",
    "    :return: 第 1 四分位数、第 2 四分位数（中位数）、第 3 四分位数\n",
    "    \"\"\"\n",
    "    series = pd.Series(data)\n",
    "    q1 = series.quantile(0.25)  # 第 1 四分位数\n",
    "    q2 = series.quantile(0.50)  # 中位数\n",
    "    q3 = series.quantile(0.75)  # 第 3 四分位数\n",
    "    return q1, q2, q3\n",
    "\n",
    "# 示例用法\n",
    "data = len_mate_data\n",
    "q1, q2, q3 = calculate_quartiles_with_pandas(data)\n",
    "print(f\"第 1 四分位数: {q1}, 中位数: {q2}, 第 3 四分位数: {q3}\")\n",
    "print('mean:',sum(len_mate_data)/len(len_mate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ccfe8504234733b39fc423a3ac1638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=48):   0%|          | 0/167441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'summary', 'id', 'len_sum'],\n",
       "    num_rows: 135384\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = train_ds.filter(lambda x: x['len_sum']>100, num_proc=48)\n",
    "train_ds = train_ds.filter(lambda x: x['len_sum']<150, num_proc=48)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds_shu = train_ds.shuffle(seed=42)\n",
    "dataset_used_A_train = train_ds_shu.select(range(0,20000))['summary']\n",
    "dataset_used_A_test = train_ds_shu.select(range(20000,22000))['summary']\n",
    "dataset_used_B_train_mem = train_ds_shu.select(range(22000,32000))['summary']\n",
    "dataset_used_B_train_non = train_ds_shu.select(range(32000,42000))['summary']\n",
    "dataset_used_B_test = train_ds_shu.select(range(42000,44000))['summary']\n",
    "\n",
    "# xsum=Dataset.from_dict({\n",
    "#     'A':{\n",
    "#         'train':dataset_used_A_train,\n",
    "#         'test':dataset_used_A_test\n",
    "#     },\n",
    "#     'B':{\n",
    "#         'train':dataset_used_B_train_mem,\n",
    "#         'test':dataset_used_B_test,\n",
    "#         'train_non':dataset_used_B_train_non\n",
    "#     }\n",
    "# })\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Data.utils import save_json,load_json\n",
    "\n",
    "path = '../Data/raw/phishing/xsum.json'\n",
    "\n",
    "save_json({\n",
    "    'A':{\n",
    "        'train':dataset_used_A_train,\n",
    "        'test':dataset_used_A_test\n",
    "    },\n",
    "    'B':{\n",
    "        'train':dataset_used_B_train_mem,\n",
    "        'test':dataset_used_B_test,\n",
    "        'train_non':dataset_used_B_train_non\n",
    "    }\n",
    "},path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGNEWS\n",
    "\n",
    "\n",
    "@inproceedings{Zhang2015CharacterlevelCN,  \n",
    "  title={Character-level Convolutional Networks for Text Classification},  \n",
    "  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},  \n",
    "  booktitle={NIPS},   \n",
    "  year={2015}  \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since fancyzhx/ag_news couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/fancyzhx___ag_news/default/0.0.0/eb185aade064a813bc0b7f42de02595523103ca4 (last modified on Thu Nov 21 01:44:31 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"fancyzhx/ag_news\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 120000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = ds['train']\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 四分位数: 196.0, 中位数: 232.0, 第 3 四分位数: 266.0\n",
      "mean: 236.477525\n"
     ]
    }
   ],
   "source": [
    "def map_len_summary(example):\n",
    "    example['len_sum']=len(example['text'])\n",
    "    return example\n",
    "\n",
    "train_ds = train_ds.map(map_len_summary,num_proc=48)\n",
    "\n",
    "\n",
    "len_mate_data = train_ds['len_sum']\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_quartiles_with_pandas(data):\n",
    "    \"\"\"\n",
    "    使用 Pandas 计算数据的四分位数\n",
    "    :param data: 数据列表或数组\n",
    "    :return: 第 1 四分位数、第 2 四分位数（中位数）、第 3 四分位数\n",
    "    \"\"\"\n",
    "    series = pd.Series(data)\n",
    "    q1 = series.quantile(0.25)  # 第 1 四分位数\n",
    "    q2 = series.quantile(0.50)  # 中位数\n",
    "    q3 = series.quantile(0.75)  # 第 3 四分位数\n",
    "    return q1, q2, q3\n",
    "\n",
    "# 示例用法\n",
    "data = len_mate_data\n",
    "q1, q2, q3 = calculate_quartiles_with_pandas(data)\n",
    "print(f\"第 1 四分位数: {q1}, 中位数: {q2}, 第 3 四分位数: {q3}\")\n",
    "print('mean:',sum(len_mate_data)/len(len_mate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a5b9e0e71740cf838076889987ade6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=48):   0%|          | 0/112440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'len_sum'],\n",
       "    num_rows: 68776\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = train_ds.filter(lambda x: x['len_sum']>150, num_proc=48)\n",
    "train_ds = train_ds.filter(lambda x: x['len_sum']<250, num_proc=48)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIKITEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"Salesforce/wikitext\", \"wikitext-103-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-merging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
