{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since fancyzhx/ag_news couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/fancyzhx___ag_news/default/0.0.0/eb185aade064a813bc0b7f42de02595523103ca4 (last modified on Thu Nov 21 01:50:51 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ['https_proxy'] = 'http://10.14.30.39:7890'\n",
    "ds = load_dataset(\"fancyzhx/ag_news\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 120000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = ds['train']\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 四分位数: 196.0, 中位数: 232.0, 第 3 四分位数: 266.0\n",
      "mean: 236.477525\n"
     ]
    }
   ],
   "source": [
    "def map_len_summary(example):\n",
    "    example['len_sum']=len(example['text'])\n",
    "    return example\n",
    "\n",
    "train_ds = train_ds.map(map_len_summary,num_proc=48)\n",
    "\n",
    "\n",
    "len_mate_data = train_ds['len_sum']\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_quartiles_with_pandas(data):\n",
    "    \"\"\"\n",
    "    使用 Pandas 计算数据的四分位数\n",
    "    :param data: 数据列表或数组\n",
    "    :return: 第 1 四分位数、第 2 四分位数（中位数）、第 3 四分位数\n",
    "    \"\"\"\n",
    "    series = pd.Series(data)\n",
    "    q1 = series.quantile(0.25)  # 第 1 四分位数\n",
    "    q2 = series.quantile(0.50)  # 中位数\n",
    "    q3 = series.quantile(0.75)  # 第 3 四分位数\n",
    "    return q1, q2, q3\n",
    "\n",
    "# 示例用法\n",
    "data = len_mate_data\n",
    "q1, q2, q3 = calculate_quartiles_with_pandas(data)\n",
    "print(f\"第 1 四分位数: {q1}, 中位数: {q2}, 第 3 四分位数: {q3}\")\n",
    "print('mean:',sum(len_mate_data)/len(len_mate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'len_sum'],\n",
       "    num_rows: 68776\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = train_ds.filter(lambda x: x['len_sum']>150, num_proc=48)\n",
    "train_ds = train_ds.filter(lambda x: x['len_sum']<250, num_proc=48)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds_shu = train_ds.shuffle(seed=42)\n",
    "dataset_used_A_train = train_ds_shu.select(range(0,20000))['text']\n",
    "dataset_used_A_test = train_ds_shu.select(range(20000,22000))['text']\n",
    "dataset_used_B_train_mem = train_ds_shu.select(range(22000,32000))['text']\n",
    "dataset_used_B_train_non = train_ds_shu.select(range(32000,42000))['text']\n",
    "dataset_used_B_test = train_ds_shu.select(range(42000,44000))['text']\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Data.utils import save_json,load_json\n",
    "\n",
    "path = '../Data/raw/phishing/agnews.json'\n",
    "\n",
    "save_json({\n",
    "    'A':{\n",
    "        'train':dataset_used_A_train,\n",
    "        'test':dataset_used_A_test\n",
    "    },\n",
    "    'B':{\n",
    "        'train':dataset_used_B_train_mem,\n",
    "        'test':dataset_used_B_test,\n",
    "        'train_non':dataset_used_B_train_non\n",
    "    }\n",
    "},path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-merging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
